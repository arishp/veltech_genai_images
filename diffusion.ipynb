{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Stable Diffusion Image Generation\n",
                "\n",
                "This notebook demonstrates how to generate images using Stable Diffusion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/arishp/Documents/Clones/workshops/GenAI_Images_Video/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "/Users/arishp/Documents/Clones/workshops/GenAI_Images_Video/.venv/lib/python3.14/site-packages/diffusers/models/transformers/transformer_kandinsky.py:168: UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
                        "  @torch.autocast(device_type=\"cuda\", dtype=torch.float32)\n",
                        "/Users/arishp/Documents/Clones/workshops/GenAI_Images_Video/.venv/lib/python3.14/site-packages/diffusers/models/transformers/transformer_kandinsky.py:272: UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
                        "  @torch.autocast(device_type=\"cuda\", dtype=torch.float32)\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "from diffusers import StableDiffusionPipeline\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup Device and Load Model\n",
                "We check if CUDA (NVIDIA GPU) or MPS (Mac Metal) is available, otherwise default to CPU.\n",
                "Then we load the Stable Diffusion pipeline. This may take a moment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: mps\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
                    ]
                }
            ],
            "source": [
                "# Check for GPU availability\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "try:\n",
                "    # Load the pipeline\n",
                "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
                "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if device == \"cuda\" else torch.float32)\n",
                "    pipe = pipe.to(device)\n",
                "    \n",
                "    # Recommended for Mac (MPS) to avoid some memory issues\n",
                "    if device == \"mps\":\n",
                "         pipe.enable_attention_slicing()\n",
                "         \n",
                "    print(\"Model loaded successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"An error occurred loading the model: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Image Generation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_image(prompt, save_path=\"generated_image.png\"):\n",
                "    \"\"\"\n",
                "    Generates an image from a text prompt using the loaded Stable Diffusion pipeline.\n",
                "\n",
                "    Args:\n",
                "        prompt (str): The text prompt to generate the image from.\n",
                "        save_path (str): The path to save the generated image.\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # Generate the image\n",
                "        print(f\"Generating image for prompt: '{prompt}'\")\n",
                "        # Note: pipe is accessed from the global scope of the notebook\n",
                "        image = pipe(prompt).images[0]\n",
                "\n",
                "        # Save the image\n",
                "        image.save(save_path)\n",
                "        print(f\"Image saved to {save_path}\")\n",
                "        return image\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"An error occurred during generation: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Execute Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
                "image = generate_image(prompt)\n",
                "\n",
                "# Display the image in the notebook if generated\n",
                "if image:\n",
                "    # Creating a thumbnail for display if needed, or just showing usage\n",
                "    display(image)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
